\documentclass[
  draft,
  linenumbers
]{agujournal2019}
\journalname{Earth's Future}

% Package calls with options
\usepackage[inline]{enumitem} % in-line lists

% Other package calls
\usepackage{
  amssymb, amsmath,   % for math symbols
  apacite,            % AGU style citations apparently
  booktabs,           % for nice tables
  graphicx,           % for figures
  natbib,             % for references
  physics,            % for physics notation
  siunitx,            % for SI notation
  xspace,             % for ie and eg
}

% Fixed-width columns
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

% Some package settings
\sisetup{round-mode=figures,round-precision=3,scientific-notation=false}
\graphicspath{{./figs/}{../fig/}} % folders of figures
\allowdisplaybreaks{} % let the align environment span multiple pages

% Use the glossaries package
\usepackage[acronym]{glossaries}
\makeglossaries
\newacronym{acc}{ACC}{anthropogenic climate change}
\newacronym{amo}{AMO}{Atlantic Multidecadal Oscillation}
\newacronym{cba}{CBA}{cost-benefit analysis}
\newacronym{enso}{ENSO}{the El Ni\~{n}o-Southern Oscillation}
\newacronym{ffa}{FFA}{flood frequency analysis}
\newacronym{gcm}{GCM}{general circulation model}
\newacronym{hmm}{HMM}{hidden Markov model}
\newacronym{iid}{IID}{independent and identically distributed}
\newacronym{ipcc}{IPCC}{International Panel on Climate Change}
\newacronym{ipo}{IPO}{Interdecadal Pacific Oscillation}
\newacronym{lbda}{LBDA}{Living Blended Drought Analysis}
\newacronym{lfv}{LFV}{low-frequency variability}
\newacronym{nao}{NAO}{North Atlantic Oscillation}
\newacronym{pdo}{PDO}{Pacific Decadal Oscillation}
\newacronym{s2d}{S2D}{seasonal to decadal}
\newacronym{s2s}{S2S}{sub-seasonal to seasonal}

% These package calls need to come last
\usepackage[hidelinks]{hyperref}
\usepackage{cleveref}

% -----------------------------------------------------------------------------
% ABSTRACT
% -----------------------------------------------------------------------------

\begin{document}

% Title and Authors
\title{Robust Adaptation to Multi-Scale Climate Variability}
\authors{James Doss-Gollin\affil{1,2}, David J. Farnham\affil{1,2}, Scott Steinschneider\affil{3}, Upmanu Lall\affil{1,2}}
\correspondingauthor{James Doss-Gollin}{james.doss-gollin@columbia.edu}
\affiliation{1}{Department of Earth and Environmental Engineering, Columbia University}
\affiliation{2}{Columbia Water Center, Columbia University}
\affiliation{3}{Department of Biological and Environmental Engineering, Cornell University}

% Key Points
\begin{keypoints}
  \item \add{Climate risk varies over the planned lifespan of a climate risk mitigation instrument}
  \item \add{We carry out stylized computational experiments to assess the bias and variance of projected future risk estimated from limited data sets}
  \item \add{Lack of data limits the identifiability of climate signals, favoring prediction of short-term risks which require less extrapolation}
\end{keypoints}

% Abstract
\begin{abstract}
  The assessment and implementation of structural or financial instruments for climate risk mitigation requires projections of future climate risk over the operational life of each proposed instrument.
  A point often neglected in the climate adaptation literature is that the physical sources of predictability differ between projects with long and short planning periods: while historical and paleo climate records \add{emphasize} \remove{highlight the role of low-frequency variability (LFV) in modulating climate extremes at} interannual to multidecadal \remove{time scales} \add{modes of variability}, \acrlong{acc} is expected to alter their occurrence at longer time scales.
  In this paper we present a set of stylized experiments to assess the uncertainties and biases involved in estimating future climate risk over a finite future period, given a limited observational record.
  These experiments consider both quasi-periodic and secular change for the underlying risk, as well as statistical models for estimating this risk from an $N$-year historical record.
  The uncertainty of \acrshort{ipcc}-like future scenarios is considered through an equivalent sample size $N$. 
  The relative importance of estimating the short- or long-term risk extremes depends on the investment life $M$\remove{ and the future discount rate for investment}.
  Shorter design lives are preferred \add{for situations} where inter-annual to decadal variability can be successfully identified and predicted, suggesting the importance of sequential investment strategies for adaptation. 
\end{abstract}

% -----------------------------------------------------------------------------
% INTRO
% -----------------------------------------------------------------------------

\section{Introduction}\label{sec:introduction}

Recent climate extremes such as floods, droughts, hurricanes, tornadoes, hailstorms, and heat waves have caused death and destruction, motivating investments in climate adaptation for the public and private sectors.
Further, rapid and continuing changes to global climate hazard and exposure underscore the need for adaptation strategies.
For example, population growth and urbanization have driven rapid increases in global exposure to events such as floods \citep{Jongman:2012cr} and tropical cyclones \citep{Peduzzi:2012iq}.
At the same time, anthropogenic modification of global and local climate processes affects the frequency, intensity, and location of extreme events \citep{IPCC:2012wt, Milly:2008dg, Shaw:2016bo}.
Even if \add{future} mitigation efforts are successful, \add{existing levels of atmospheric $\text{CO}_2$ and ocean heat content necessitate the development of} novel adaptation strategies\remove{ are needed}.

This need has motivated a multitude of approaches for estimating the probability distribution of future climate risk, and for choosing between different risk mitigation instruments based on these estimates \citep[see, e.g.\@\xspace,][]{Merz:2014gf}.
\add{A typical goal is to create systems which are robust in the sense that they perform well over a wide range of plausible futures} \citep{lempert:2007,Borgomeo:2018hk} \add{and which fail along non-catastrophic modes} \citep{brown:2010}.
Although climate risk has traditionally been managed with centrally planned structural instruments (e.g.\@\xspace, a levee), the high price \citep{Papakonstantinou:2016ve}, environmental costs \citep{dugan:2010}, and vulnerability to biased climate projections \citep{lempert:2007} have recently \remove{slowed their implementation}\add{dampened enthusiasm}.
\remove{Instead}\add{Rather}, actors such as New York City have turned to a combination of structural\add{ (e.g.\@\xspace, stormwater barrier)}, operational\add{ (e.g.\@\xspace, improved evacuation routes)}, and financial\add{ (e.g.\@\xspace, index insurance)} instruments for reducing vulnerability and increasing resilience to climate extremes \citep{CityofNewYork:2013uh}.
These instruments are not typically implemented in isolation or statically.
Instead, investment decisions made at each point in time affect the viability, costs, and benefits of future decisions, causing the system to trace a ``pathway'' through time \citep{Walker:2013gi,Haasnoot:2013im,Haasnoot:2015dh}.

Despite recent insights, important questions remain.
How should a portfolio of risk mitigation instruments be optimized?
How should one choose between permanent and transient instruments?
Under what conditions is a permanent, large infrastructure investment required, and what information is needed to recognize this threshold?
In this paper we focus on \add{the narrower question of} how the temporal structure of climate risk, and the uncertainties associated with \add{its estimation}\remove{estimating it}, influence the answers to these questions.
We continue this section with three specific observations about climate risk which, while \remove{apparently}\add{seemingly} obvious, have important and subtle implications \add{that}\remove{which} we examine in \cref{sec:methods,sec:results,sec:discussion-conclusions}.

\subsection{Planning decisions are made with finite horizons}\label{sec:intro-finite}

Public or private sector investments in climate adaptation require not only the design of each potential structural instrument, but also selecting between instruments with vastly different operational planning periods.
This project planning period, which we define as being $M$ years, describes the nominal economic or physical lifespan of the structure or contract.
Typical planning periods may vary from $M=1$ year or less for a financial contract to $M=100$ years or longer for a structural instrument, as illustrated in \cref{tab:real-world-M}.
The planning period can also be interpreted as the finite period over which \gls{cba} is conducted when assessing the project.

\noindent\begin{table}
  {\footnotesize
    \begin{tabular}{L{1in}L{2.5in}L{0.3in}L{1.7in}}
      \toprule
      Location & Description & $M$ & Reference \\
      \midrule
      Iowa River & Purchase options for inundation of downstream agricultural lands to allow higher release flows from the flood control reservoir & 1 & \citet{Spence:2016ca} \\
      New York City & Catastrophe bond for protection against storm surge caused by named storms and earthquakes & 3 &  \\
      County of Santa Barbara, California & Emergency improvements to portions of the Santa Maria Levee to reduce risk of levee failure & 5 & \citet{USACE:2007ta} \\
      Iowa River & Raise levees by 6 feet & 30 & \citet{Spence:2016ca} \\
      Dallas, TX & Evacuation of Rockefeller Boulevard & 50 & \citet{USACE:2014vn} \\
      Central California & Tulare Lake storage and floodwater protection project & 100 & \citet{GEI:gIaEZ-gS} \\
      \bottomrule
    \end{tabular}
    \caption{
      Six real-world risk mitigation instruments and the associated project planning period ($M$).
    }\label{tab:real-world-M}
  }
\end{table}

Typical climate risk management policies do not use a single risk mitigation instrument, but rather build a portfolio of several instruments.
Each has its own operational period, which may or may not match the planning horizon of the portfolio as a whole.
This means that even if the portfolio has a long planning period, i.e.\@\xspace if long-term plans are a priority, this goal may be best accomplished through a series of flexible and adaptive instruments with short individual planning periods.
\add{For example, the action that New York City can take today which best protects against uncertain hurricane risks over the 21st century could potentially be to purchase insurance and defer more permanent allocation of capital until some uncertainties are resolved.}
The costs and benefits of each individual instrument will be assessed over its individual, finite planning period, but decisions about the portfolio structure are evaluated over the longer planning horizon.

The availability of precise climate information in the near future may significantly alter the choice between a large, long-duration instrument and a sequence of smaller, short duration instruments that can be executed quickly.
For example, if above-average climate risk is projected over the next few years, a more costly project might be justified.
However, in the plausible case of a long construction period for the large, permanent instrument, a financial risk mitigation instrument might be needed in the immediate term to cover potential losses before the large project is completed.
Conversely, if the near-term risk is projected to be low, then deferral of the large, potentially expensive instrument may be warranted.
These cases highlight how the precision of short- and long-term climate risk projections plays directly into climate adaptation.

\subsection{Climate risk varies on many scales}\label{sec:intro-lfv}

Climate risk is governed by a variety of physical processes which occur on scales ranging from local and transient to global and permanent.
Of these processes, \gls{acc} has received the most attention in the climate adaptation literature and its influence on some river floods, droughts, hurricanes, urban flooding, and many other climate hazards has been the subject of substantial investigation \citep[e.g.\@\xspace,][]{Coumou:2012bc,Milly:2008dg,OGorman:2009hj,Trenberth:2003bj}.
Human activities can also affect climate risk through modification of local land or river systems \citep[see][]{Merz:2014gf}, and through changes in exposure to extremes \citep{baldassarre:2018,Jongman:2012cr}.
In combination, these effects highlight that the past may not be an adequate representation of future climate risk \citep[termed ``nonstationarity'' by][]{Milly:2008dg}.

Secular change is not the only mechanism which can cause historical records to provide a biased view of future risk.
The Hurst phenomenon is well known and identified with long memory processes in geophysics, physics, biology, medicine, traffic, network dynamics, and finance \citep{oconnell:2016}.
The extensive observations of such behavior in hydrologic and climatic time series emphasize the need to consider such processes as underlying any discussion of climate change or nonstationarity \citep{koutsoyiannis:2003,markonis:2013,Palmer:1993ef}.
The Hurst phenomenon has also been connected to low frequency quasi-periodic phenomenon, especially where fractal scaling is expected.
For example, wavelet methods have been used to estimate the Hurst exponent \citep{simonsen:1998,chamoli:2007}, and to design simulation algorithms that reproduce self-similarity, long range dependence and quasi-periodic regimes \citep{Kwon:2007fj,bullmore:2001,geweke:1983,feng:2005}.
The Hurst phenomenon also provides a link between catchment hydrology and global climate dynamics \citep{bloschl:2010,montanari:2003}.
The Hurst exponent is directly related to the fractal dimension of a process, and there is a rich multi-disciplinary literature as to the process level and statistical justification of long memory and fractal processes in hydrology \citep{mandelbrot:1985,mandelbrot:1969,beran:1994}.
These processes have also been used to describe multi-scale dynamics of the climate \citep{lovejoy:2012,lovejoy:2013a,lovejoy:2013,selvam:2017}, including \gls{enso} \citep{maruyama:2018,zivkovic:2013} and the \gls{pdo} \citep{Mantua:1997kj}.

External forcing from structured climate signals \citep[``teleconnections'';][]{Angstrom:1935ej} and catchment dynamics are both useful in explaining the \gls{lfv} observed in natural hydroclimate time series.
We illustrate such \gls{lfv} in \cref{fig:observed-lfv}, which shows a \SI{500}{year} drought reconstruction from the \gls{lbda} \citep{Cook:2010bz}, a \SI{100}{year} record of annual maximum streamflowflow on the American River at Folsom, and the global wavelet power spectrum for both \citep{Torrence:1998jp,Roesch:wlBQQoIs}.
Peaks for the American River time series are apparent at approximately 2 and 15 years and in the \gls{lbda} time series at approximately 8, 20, and 64 years.
This is illustrated by the blue line in \remove{the top left panel of} \cref{fig:observed-lfv}\add{(b)}, which shows a \SI{20}{year} moving average of the \gls{lbda} time series.
A detailed analysis of these time series is beyond the scope of this paper, but we note that the high amplitude and long time periods of the quasi-periodic oscillations they exhibit are consistent with analyses of \gls{lfv} in other hydroclimate systems \citep{Kiem:2002kq,Swierczynski:2012km,Woollings:2014kd,Hodgkins:2017hw}.
The key implication is that the observations, \citep{Jain:2001hz}, trends \citep{bhattacharya:1983}, and frequencies \citep{newman:2016} observed in the past are often poor predictors of future behavior.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{observed-lfv.pdf}
  \caption{
    Hydroclimate time series vary on many time scales.
    (a) A \SI{500}{year} reconstruction of summer rainfall over Arizona from the \acrfull{lbda}.
    \remove{High numbers}\add{Lower values} indicate more severe drought.
    A 20-year running mean is also shown in blue.
    (b) A \SI{100}{year} record of annual-maximum streamflow for the American River at Folsom.
    Daily streamflow values were divided by the catchment area to yield a normalized flow in units of \si{\milli\meter\per\day}.
    (c) The global wavelet power spectrum of the \gls{lbda} time series (a).
    Blue (red) dots indicate frequencies which are significant at $\alpha=0.10(0.05)$ compared to white noise.
    (d) Global wavelet power spectrum, like (c), for the American River data.
  }\label{fig:observed-lfv}
\end{figure}

\subsection{The dominant processes depend on the planning period}\label{sec:intro-dominant}

Evaluating a particular risk mitigation instrument involves projecting climate risk over the $M$-year planning period.
Consequently, the physical mechanisms which impart predictability on the system differ between projects with long and short planning periods.
As illustrated in \cref{fig:conceptual-sketch} (a), the lifetime risk of a permanent structure with a \SI{100}{year} planning period depends on the magnitude and extent of future human activities, with very large associated uncertainty.
Even \remove{with} \add{in the idealized and unrealistic case of} a perfect climate model, these uncertainties will be large.
By contrast, this perfect climate model may usefully inform estimates of climate hazard over a three-year insurance contract with much less associated uncertainty.

Of course, scientists are not equipped with perfect models.
Since different physical processes control climate risk at different timescales, successful integration of climate projections into decision frameworks depends on identifying, and subsequently predicting, these processes.
A key question is whether the limited information in an $N$-year observational record permits the identification and projection of cyclical climate variability and secular change, and what the resulting bias and uncertainty portend\remove{s} for risk mitigation instruments with a planning period ranging from a few years to several decades.
As shown in \cref{fig:conceptual-sketch} (b), the combination of \gls{lfv}, stochastic variability, and secular change in a limited record can lead to large uncertainty in estimated future risk.
Although \cref{fig:conceptual-sketch} focuses on physical processes, similar conclusions would also be valid for the socioeconomic processes which drive exposure to floods and other hydroclimate hazards.

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{conceptual-sketch.pdf}
  \caption{
    A stylized illustration of (a) irreducible and (b) estimation uncertainty.
    (a): Irreducible uncertainty cannot be resolved with better models or data and is dominated in the short term by chaotic behavior of the climate, and in the long term by the uncertainty in future \acrlong{acc}.
    (b): Informational uncertainty limits the potential to identify different climate signals.
    The blue line shows an idealized climate signal and the black line shows observations, which are scattered stochastically around the signal line.
    The green shading shows the true range within which observations will occur 95\% of the time, while the gray shading the 95\% confidence interval as estimated with a linear trend model.
    }\label{fig:conceptual-sketch}
\end{figure}

% -----------------------------------------------------------------------------
% METHODS
% -----------------------------------------------------------------------------

\section{Methods}\label{sec:methods}

We consider a set of stylized experiments to assess how well one can identify and predict risk associated with cyclical and secular climate signals for the $M$-year planning period and the probability of over- or under-design of a climate adaptation strategy based on these projections.
We consider different temporal structures for the underlying risk which encompass quasi-periodic, regime-like, and secular change, as well as simple statistical models for estimating this risk from an $N$-year historical record.
The relative importance of estimating the short- or long-term risk associated with these extremes depends on the design life $M$, but the potential to understand and predict these different types of variability depends on the informational uncertainty in the $N$-year historical record.
Though we illustrate our findings with a simple flood risk example, the conclusions drawn apply to other hydroclimate hazards, and in particular those typically characterized through a time series of annual maxima or minima.

We consider three scenarios for climate risk, which we define by the structure of the underlying climate \annote{signal}{changed the order}:
\begin{enumerate*}[label= (\roman*)]
  \item secular change only;
  \item \gls{lfv} only; and
  \item \gls{lfv} plus secular change.
\end{enumerate*}
For each scenario, and for its identification from the $N$ year length historical data, the bias and variance of the estimated flood risk over the $M$ year design life relative to the ``true model'' are computed.
We repeat the simulations $J = 1000$ times for each combination of experiment parameters to obtain estimates of the expected bias and variance for each scenario given $M$ and $N$ (\cref{sec:methods-evaluating}).

We caution the reader that the models for sampling climate risk (\cref{sec:methods-generating}) and for statistically projecting future risk (\cref{sec:methods-estimating}) were chosen for their intuitive interpretation, rather than their general validity \citep[see][for a thoughtful discussion of the value of simple models]{Held:2005cj}.
We do not, in general, endorse these models for practical use but instead argue that the conclusions drawn from these simple models may be straightforwardly applied to more complex and realistic models.
This discussion continues in \cref{sec:discussion-conclusions}.

\subsection{Sampling Climate Risk}\label{sec:methods-generating}

The first step is to sample climate risk by generating synthetic streamflow sequences.
To do this, we model  annual-maximum flood peaks with a log-normal distribution, conditional on a location parameter which varies in time:
\begin{equation} \label{eq:log-normal}
  \log Q(t) \sim \mathcal{N} \qty(\mu(t), \sigma(t)).
\end{equation}
We further assume a constant coefficient of variation of the log streamflow,
\begin{equation}
  \sigma(t) = \xi \mu(t)  
\end{equation}
and apply a lower threshold on the standard deviation
\begin{equation}
  \sigma(t) \geq \sigma_\text{min} > 0.
\end{equation}
This formulation describes \add{all} scenarios \add{for future climate considered in this paper within} \remove{in} a single equation\remove{;}\add{.}
\add{To add climate variability to the system,} the only component which needs to change is the dependence of $\mu(t)$ on time, which we parameterize as
\begin{equation}\label{eq:nino3}
  \mu(t) = \mu_0 + \beta x(t) + \gamma \qty(t - t_0),
\end{equation}
where $x(t)$ represents a climate time series which itself exhibits \gls{lfv} but not secular change.
This parameterization is analagous to the ``climate-informed'' approach described in several studies for estimating climate risk \citep{Delgado:2014ey,Merz:2014gf,Farnham:2018gs}.
Following \cref{eq:nino3}, when $\beta \neq 0$ there will be \gls{lfv}, and when $\gamma \neq 0$ there will be secular change.
The values of all parameters used for sampling climate risk are listed in the online supporting information for each of the three scenarios considered.

We represent the climate state variable $x(t)$ through an index for \gls{enso}, which has been shown to impact flood risk around the world \citep{Ropelewski:1987do, Ward:2014gg} and has characteristic variability on timescales of 3 to 7 years \citep{Sarachik:2009dr} as well as a ``staircase'' of lower-frequency scales \citep{Jin:1994wq}.
We model \gls{enso} variability by taking a \SI{20000}{year} integration of the Cane-Zebiak model \citep{Zebiak:1987cl} to produce a monthly NINO3 index \citep{Ramesh:2016hf}.
To create an annual time series, we average the October-December values of the NINO3 index for each year.
Supplemental figure S1 shows a wavelet spectrum and time series plot of the resulting annual time series.
In the online supplemental information we consider an alternative parameterization of $\mu(t)$, \remove{i.e.\@\xspace an alternative to,} which considers a Markovian state transition rather than an explicit \gls{enso} model, and note a general agreement of results.

\subsection{Projecting Climate Risk over the Future $M$ years}\label{sec:methods-estimating}

Once a synthetic streamflow sequence has been generated, we evaluate the identifiability and predictability of the dominant climate modes by fitting the sequence to statistical models and creating probabilistic projections of the future.
We use three well-studied statistical methods for future flood risk, each of which parameterizes time in a different way.
One is purely stationary, another captures \gls{lfv}, and the third captures secular change.
We choose these models for their interpretability and simplicity, rather than because of a belief that they are generally valid.
For each synthetic flood sequence to be analyzed, the first $N$ years are treated as observations.
Once a statistical model is fit to these \remove{``}observations\remove{''}, then $K=\num{1000}$ sequences of future annual-maximum streamflow over the future $M$-year record are generated from the fitted model using Monte Carlo simulation.

\add{In the first case we} \remove{We first consider fitting}\add{fit} a stationary model to the observed flood record, following classical assumptions of \gls{iid} sequences.
In this model annual-maximum streamflow are taken to follow a log-normal distribution with constant mean and variance.
\add{We refer to this model as ``LN2 Stationary.''}
The parameters of the model are fit  in a Bayesian framework to fully represent the posterior uncertainty, using the stan probabilistic computing package \citep{Carpenter:2017ke} with weakly informative priors \citep{gelman:2017,simpson:2017}.
The full model, including priors, is given in supplemental equation (S1).

Next, we modify this stationary model to incorporate secular change.
Many studies have done this by regressing certain parameters of the model on time \citep[see][for a comprehensive review]{Salas:2018ge}.
We consider an extension of the stationary log-normal model by adding a time trend on the scale parameter and maintaining a constant coefficient of variation, as given in supplemental equation (S2).
\add{We refer to this model as ``LN2 Linear Trend''}
This model gives a lower bound on total informational uncertainty because it correctly represents the trend's known form, whereas in real-world analyses the form of the trend is unknown.

\remove{We finally consider}\add{Finally, we explicitly model} \remove{a HMM which explicitly represents}\gls{lfv} \add{using a} \gls{hmm}.
An \gls{hmm} is a latent variable model in which the system being modeled is assumed to follow a Markov process with unobserved (i.e.\@\xspace hidden) states $S(t)$ \citep{Rabiner:1986jk}.
The (unobserved) states evolve following a first-order Markov process, and the observed variable (e.g.\@\xspace streamflow) depends only on the underlying state.
\Glspl{hmm} have been widely used for modeling streamflow sequences \citep{Bracken:2016ba} and \gls{enso} \citep{rojohernandez:2017}.
We fit  streamflow sequences using a \gls{hmm} with two states.
The model is fit using the Baum-Welch algorithm, assuming that the data follow a log-normal distribution \remove{conditional only on the state}\add{that is conditional only on the unobserved state variables}.
This algorithm simultaneously estimates the transition matrix of the Markov process and the conditional parameters of each distribution.
For simplicity, we fit only a two-state \gls{hmm} to each sequence.
Future floods are then estimated by simulating future states from the estimated transition matrix and then drawing $Q(t)$ conditional on the simulated state.

\subsection{Evaluating Fitting Models}\label{sec:methods-evaluating}

Both estimation bias and estimation uncertainty affect the utility of a climate risk projection, as illustrated in \cref{fig:conceptual-bias-variance}.
An instrument \add{whose design was based on projections with} \remove{designed based on} overestimated variance \remove{and}\add{or} positive bias will be over-designed, either causing the risk manager to avoid the investment, given its higher cost, or will lead to unnecessary diversion of funds from other instruments.
Similarly, an instrument designed based on underestimated variance or negative bias may be under-designed, and thus fail to protect the \remove{user}\add{public}.
\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{Bias-Variance-Sketch.pdf}
  \caption{
    Consequences of model bias or incorrect model representation of uncertainty.
    If an estimate has a positive bias and overestimates uncertainty, the instrument may be too expensive.
    If an estimate has negative bias and underestimates uncertainty, it will be likely to fail.
  }\label{fig:conceptual-bias-variance}
\end{figure}

We evaluate both the estimation bias and estimation uncertainty.
For a given choice of $M$, $N$, \add{and} generating model, we compare the synthetic streamflow sequence's $N$-year ``historical record'' and the $K=1000$ posterior simulations of future flows.
The quantity $\hat{p}_T$, the estimated expected number of floods per year, is taken by calculating, for each of the $K$ posterior simulations, the number of exceedances of the flood design threshold, then dividing by $M$ to get exceedances per year.
We then compute the variance of these $K$ estimates.
We further calculate the bias of $\hat{p}_T$ by averaging it across the $K$ samples and comparing this to the number of times the $M$-year ``future period'' of the synthetic streamflow sequence exceeds the flood design threshold.
Since the ``observed'' number of flood exceedances from the generating model is inherently noisy for an $M$-year period, we average the bias and variance across $J=1000$ different streamflow sequences to compute expected values of both.
These sequences are generated with the same underlying parameters, but the specific synthetic NINO3 sequence (or set of Markov states) may differ between the $J$ sequences.

\subsection{Experiment design}\label{sec:methods-computation}

\Cref{fig:flowchart} describes the experimental design.
We assess estimation bias and variance for three \remove{cases}\add{scenarios of future climate}.
First, we consider an idealized scenario where only secular change is present in the system and \gls{lfv} is fully damped (``secular change only'').
Next, we consider the ``pre-industrial'' case where there is no secular change but \gls{lfv} modulates climate risk in time (``\acrlong{lfv} only'').
Finally, we consider a more realistic (though still idealized) case with both \gls{lfv} and secular change (``\acrlong{lfv} plus secular change'').
Model parameters for each scenario are given in the supplemental methods section of the online supporting materials.

\begin{figure}
  \includegraphics[width=\textwidth]{flowchart.pdf}
  \caption{
    Flow chart describing experiment design.
    Parameters are shown in red.
    Calculated quantities are shown in white.
    Quantities used for analysis are shown in blue.
  }\label{fig:flowchart}
\end{figure}

Computation was carried out in the python programming language, making particular use of the matplotlib, numpy, pandas, pomegranate, scipy, and xarray libraries for scientific computing \citep{Hunter:2007ih, vanderWalt:2011dp, McKinney:2010un, schreiber:2017, Jones:2001uv, Hoyer:2017hs}.
Wavelet analysis was conducted using the WaveletComp package \citep{Roesch:wlBQQoIs} in the R programming language.
Bayesian models were written in the stan probabilistic programming language \citep{Carpenter:2017ke} using the No U-Turn Sampler \citep{Hoffman:2011wm,Betancourt:2017vd}.
The codes used to generate the figures and text of this paper are available at \url{https://github.com/jdossgollin/2018-robust-adaptation-cyclical-risk} or in the online supplemental material of this paper.

% -----------------------------------------------------------------------------
% RESULTS
% -----------------------------------------------------------------------------

\section{Results}\label{sec:results}

These three \remove{cases}\add{scenarios for future climate considered} are illustrated in \cref{fig:example-fit}, which shows a single synthetic streamflow sequence generated with $N=50$ and $M=100$.
\add{We also show projected future climate risk} with each of the three \remove{fitting}\add{estimating} models \add{described in} \cref{sec:methods-estimating}\remove{are also shown}.
This figure highlights that even where projections of average streamflow are unbiased, if the spread is too large then projection of the threshold exceedance probability may be too large.
In the remainder of this section we present a more systematic analysis of each of these three cases.

\begin{figure}
  \includegraphics[width=\textwidth]{Example-NINO3-M100-N50.pdf}
  \caption{
    An illustration of the estimation procedure.
    A single streamflow sequence with $N=50$ and $M=100$ is shown for each of the three cases (secular only, \gls{lfv} only, and secular plus \gls{lfv}) considered.
    The blue line shows the observed sequence.
    The gray shading indicates the 50\% and 95\% confidence intervals using each of the three fitting methods discussed (rows).
    The horizontal black line indicates the flood threshold.
  }\label{fig:example-fit}
\end{figure}

\subsection{Secular Change Only}

In the idealized case where only secular change exists, accurate climate predictions need to either use a long record to identify and model this trend, or to ignore the trend and predict only a few years ahead.
This is shown in \cref{fig:secular-nino3-bias-variance}, which depicts the estimation bias and variance for each of the three estimation models for many combinations of $M$ and $N$.

The log-normal trend model tends to over-estimate risk (positive bias), except when $N$ is large, because the model gives a non-zero probability to the trend being larger than it actually is.
The variance of these estimates is also large.
This again highlights the difficulty of fitting complex models for estimating risk when informational uncertainty is large.
By contrast, the stationary log-normal model and \gls{hmm}, which do not account for secular change, show relatively low variance of their estimates and exhibit low bias for short $M$.
As $N \rightarrow \infty$, these (mis-specified) models can only represent the trend by setting the scale parameter very large, leading to high estimation variance and (as $M \rightarrow \infty$) also a large bias.
This principle has prompted some to consider only the most recent years of the data, deliberately shortening $N$ \citep[i.e.\@\xspace,][]{Muller:2014fc}.
However, these results also highlight that the increase in variance as $N$ is reduced may quickly outpace the utility of any bias reductions.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{secular-only-nino3-bias-variance.pdf}
  \caption{
    Expected estimation bias and variance for sequences generated with secular change only (no \gls{lfv}).
    Sequences were fit to each of three statistical models (columns) for different $N$ and $M$ ($x$ and $y$ axis, respectively).
    Top row shows estimation bias and bottom row shows log standard deviation of estimates.
    Note the uneven spacing of the $x$ and $y$ axes.
  }\label{fig:secular-nino3-bias-variance}
\end{figure}

If the analyst could know \emph{a priori} that secular change is present in a time series, and if $M$ is long, then the use of a complex model which represents the processes causing this change is required.
Here the log-normal linear trend model has the advantage of being correctly specified (both the generating and fitting processes assume a log-normal distribution conditional on a linear time trend), which is generally not the case in the real world \citep{Montanari:2014hl,Serinaldi:2015bq}.
As a result, in real-world settings longer $N$ may be required to identify trends whose exact form is not known.
Alternatively, if $M$ is small then it may be reasonable to use a stationary estimate, since the bias will be small and the variance substantially lower.

\subsection{Low-Frequency Variability Only}

We next turn to the idealized case where  \gls{lfv} is present but there is no secular change in the system.
\Cref{fig:lfv-nino3-bias-variance} highlights that identification of nonexistent trends from limited data may lead to gross over-estimation of true risk through an increase in the variance of the estimated risk.
As expected, the stationary log-normal model performs well overall, with low bias and low variance.
The \gls{hmm} actually out-performs the stationary model, with slightly lower variance than the stationary model, because it better captures the multimodal distribution that emerges from dependence on the \gls{enso} index, which exhibits several regimes (see supplemental figure S1).
By contrast, the linear trend model performs poorly for low $N$ and high $M$ because a positive probability is assigned to the existence of a positive trend.

Of particular relevance to analysis of real-world data sets is the ratio of the project planning period $M$ to the characteristic periods of variability of the \gls{lfv}.
If this period is much larger than $M$, then a stationary assumption may provide reasonable estimates, and fewer observations may be required (shorter $N$).
As shown in supplemental figure S1, the \gls{enso} time series is most active in the \SIrange{3}{6}{year} band.
In the real world, however, many hydroclimate time series vary at multidecadal and longer frequencies.
In this case, as illustrated in \cref{fig:conceptual-sketch}, the characteristic periods may be as large or larger than $M$, particularly if multidecadal modes such as the \gls{pdo} or \gls{amo} are involved, and the \gls{lfv} must therefore be estimated explicitly.
This in turn requires a longer observational record $N$ in order to identify and predict these different signals.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{lfv-only-nino3-bias-variance.pdf}
  \caption{
    As \cref{fig:secular-nino3-bias-variance} but for sequences generated with zero secular change and strong \gls{lfv}.
  }\label{fig:lfv-nino3-bias-variance}
\end{figure}

\subsection{Low-Frequency Variability and Secular Change}

In the final and most realistic case, where both \gls{lfv} and secular change are present, stationary models perform well for short $M$ while for long $M$ the trend must be identified from a long record and modeled explicitly.

Consistent with the conceptual illustration of \cref{fig:conceptual-sketch}, the results of \cref{fig:lfv-secular-nino3-bias-variance} highlight that the relative importance of secular change and \gls{lfv} depends on $M$.
When $M$ is long, climate risk is dominated by secular change and it becomes essential to model this risk explicitly with a more complex model (i.e.\@\xspace, the linear trend model).
Alternatively, when $M$ is short, \gls{lfv} dominates and the increased variance associated with estimating a trend is not worth the modest reduction in bias.
As before, when the informational uncertainty is large (small $N$), the identifiability and predictability of the trend are  limited.
\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{lfv-secular-nino3-bias-variance.pdf}
  \caption{
    As \cref{fig:secular-nino3-bias-variance} but for sequences generated with both \gls{lfv} and secular change.
  }\label{fig:lfv-secular-nino3-bias-variance}
\end{figure}

% -----------------------------------------------------------------------------
% DISCUSSION
% -----------------------------------------------------------------------------

\clearpage
\section{Discussion}\label{sec:discussion-conclusions}

Evaluating and implementing investments for climate risk mitigation involves making projections of climate risk, which generally exhibits both \gls{lfv} and secular trends, over the $M$-year project life of the instrument.
The success of this prediction will depend on the identifiability of different signals from limited information, the time scales of \gls{lfv} relative to the project life of the instrument, and the degree of intrinsic uncertainty in the system.
In this paper we took a synthetic data approach to explore the implications of varying $M$ and $N$ in stylized scenarios that represent important features of real-world hydroclimate systems.

\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{M-N-Sketch.pdf}
  \caption{
    The importance of predicting different signals, and the identifiability and predictability of the signals, depends on the degree of informational uncertainty ($N$) and the project planning period ($M$).
  }\label{fig:m-n-sketch}
\end{figure}

\Cref{fig:lfv-secular-nino3-bias-variance,fig:lfv-secular-nino3-bias-variance,fig:secular-nino3-bias-variance} \add{show that} for projects where $M$ is sufficiently short, intrinsic uncertainty is low and cyclical climate variability is dominant over the project planning period \citep{Jain:2001hz,Hodgkins:2017hw}.
However, one's ability to identify and predict this variability depends on having a model of sufficient complexity to represent the processes that cause \gls{lfv}, and the data to fit the model.
In this case, the project may be in the ``potential predictability zone'' of \cref{fig:m-n-sketch}.
If sufficient information is not available, however, then simple models which represent fewer processes may be preferred (the ``rough guess zone'').

For projects with longer $M$, \add{our results highlight the importance of identifying and predicting} \remove{it becomes necessary to consider the role of} secular change.
As illustrated schematically in \cref{fig:conceptual-sketch}, uncertainties as to future population, economic development, renewable energy technology, and greenhouse gas mitigation collectively lead to very high intrinsic uncertainty in projections of future climate risk.
As the physical mechanisms cascade from global (e.g.\@\xspace, global mean surface temperature) to regional  \citep[e.g.\@\xspace, storm track position;][]{Barnes:2015gl} and local (e.g.\@\xspace, annual-maximum streamflows) scales, informational uncertainties also compound and increase \citep{Dittes:2017he}.
With sufficient information (large $N$), this informational uncertainty may be reduced, but this data cannot address intrinsic uncertainty and this zone is thus named the ``intrinsic uncertainty zone''.
Finally, if $N$ is limited then there will be strong potential for misleading estimates and over-extrapolation \add{(i.e.\xspace} a ``danger zone''\add{ for planning)}.

These findings were derived \add{conceptually and through} \remove{using simple models} \add{idealized computational experiments} for \add{simulating and predicting climate} risk\remove{ projection}, but the principles are applicable to more complex, physically based methods.
For example, flood frequency analysis may join observations across time and space \citep{Lima:2016kd,Merz:2008eh} or apply model chains based on general circulation models and hydrologic models \citep[see][]{Merz:2014gf} to increase $N$.
We suggest that the sample size $N$ defined in our experiments may be straightforwardly interpreted as a measure of the total informational uncertainty in the analysis; as $N$ increases, informational uncertainty decreases.

Similarly, real-world climate adaptation plans will typically include multiple instruments which may be placed in different locations and times in a sequential fashion.
Even if the planning period of a portfolio is long, the individual instruments within the portfolio may have short planning periods.
Since \cref{sec:results} shows that the bias and variance of climate risk projections tend to increase with $M$, the total bias and variance associated with sequencing 20 consecutive $M=\SI{5}{year}$ projects will be less than that associated with making a single $M=\SI{100}{year}$ project.
This effect will be compounded by the fact that if the first $M=\SI{5}{year}$ project is based on estimates with informational uncertainty $N$, the second will have $N+5$, the third $N+10$, and so on.

The climate adaptation decisions which our analysis can inform are typically framed as economic cost-benefit analyses which discount future cash flows at some annual rate \citep{sodastrom:1999,powers:2003}.
The application of a positive discount rate, mandated for many public sector projects in the United States \citep{powers:2003}, further emphasizes the importance of predicting near-term risk.
Projects with long planning periods must therefore overcome future discounting, the potential for large bias or variance, and that all estimates are made with informational uncertainty $N$.
\add{By contrast, the informational uncertainties for a sequence of short-term instruments are $N, N+M, N+2M, \ldots$, potentially yielding improved identifiability and predictability of relevant climate signals.}\remove{rather than a sequence of $N$, $N+\Delta N, \ldots$}.

\section{Summary}

In this paper we considered how the temporal structure of the climate affects the potential for successful prediction over a finite $M$-year future period.
We began with three premises, or observations, about the nature of climate risk:
\begin{enumerate*}[label= (\roman*)]
  \item that \remove{planning decisions are made with finite horizons}\add{different climate risk mitigation instruments have different planned lifespans};
  \item that climate risk varies on many scales; and
  \item that the processes which dominate this risk over the planning period depend on the planning period itself.
\end{enumerate*}
Although the simulations presented here are neatly divided into secular change, \gls{lfv} only, and \gls{lfv} plus secular change, real-world hydroclimate time series exhibit \gls{lfv} on many timescales and several sources of (not necessarily linear) secular change, adding further informational and intrinsic uncertainties.

Depending on the specific climate mechanisms that impact a particular site, and the predictability thereof, the cost and risk associated with a sequence of short-term adaptation projects may be lower than with building a single, permanent structure to prepare for a worst-case scenario far into the future.
For most large actors, a portfolio of both large $M$ and small $M$ projects will likely be necessary, none of which precludes the need for mitigation of global and local climate change and the development or the execution of vulnerability reduction strategies.

% -----------------------------------------------------------------------------
% END MATTER
% -----------------------------------------------------------------------------

\acknowledgments

The authors thank Dr. Alberto Montanari and one anonymous reviewer for insightful comments on this manuscript.
The authors thank Nandini Ramesh of Columbia University for providing the synthetic NINO3 index from a \SI{100000}{year} run of the Cane-Zebiak model as described in \citet{Ramesh:2016hf}.
The authors thank John High of the United States Army Corps of Engineers for providing the naturalized daily streamflows at the Folsom Dam.
JDG thanks the NSF GRFP program (grant DGE 16-44869: ``Understanding \& Predicting Climate Drivers of Extreme, Mid-latitude River Floods'') and SERDP program (grant 2516: ``Climate Informed Estimation of Hydrologic Extremes for Robust Adaptation to Non-Stationary Climate'') for support.

\bibliography{library}

\end{document}
